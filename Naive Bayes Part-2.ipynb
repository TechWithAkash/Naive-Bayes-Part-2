{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be8a22d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Q1. Probability of an Employee Being a Smoker Given They Use the Health Insurance Plan\n",
    "We can solve this using Bayes' theorem.\n",
    "Given:\n",
    "- Probability of using the health insurance plan: P(Uses Plan) = 0.70\n",
    "- Probability of smokers among those who use the plan: P(Smoker | Uses Plan) = 0.40\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\\[ P(Smoker | Uses Plan) = \\frac{P(Uses Plan | Smoker) \\times P(Smoker)}{P(Uses Plan)} \\]\n",
    "\n",
    "We're given \\(P(Smoker | Uses Plan)\\) and \\(P(Uses Plan)\\). We can calculate \\(P(Smoker)\\) using the formula for conditional probability:\n",
    "\n",
    "\\[ P(Smoker) = P(Smoker | Uses Plan) \\times P(Uses Plan) \\]\n",
    "\n",
    "Now, let's calculate:\n",
    "\\[ P(Smoker) = 0.40 \\times 0.70 = 0.28 \\]\n",
    "\\[ P(Smoker | Uses Plan) = \\frac{P(Uses Plan | Smoker) \\times P(Smoker)}{P(Uses Plan)} = \\frac{0.40 \\times 0.28}{0.70} = 0.16 \\]\n",
    "\n",
    "Therefore, the probability that an employee is a smoker given that they use the health insurance plan is **0.16** or **16%**.\n",
    "\n",
    "### Q2. Difference Between Bernoulli Naive Bayes and Multinomial Naive Bayes\n",
    "- **Bernoulli Naive Bayes**: It assumes that all features are binary (0 or 1), making it suitable for binary feature datasets. It models the presence or absence of each feature.\n",
    "- **Multinomial Naive Bayes**: It is suitable for datasets with features representing discrete counts. It counts the occurrences of each feature's value.\n",
    "\n",
    "### Q3. How Bernoulli Naive Bayes Handles Missing Values\n",
    "Bernoulli Naive Bayes considers missing values as an additional category or feature state, depending on the implementation. In scikit-learn, missing values can be represented as zeros or ones, which are then treated as another category.\n",
    "\n",
    "### Q4. Can Gaussian Naive Bayes be Used for Multi-class Classification?\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. It assumes that continuous features follow a Gaussian (normal) distribution, and it's commonly applied to problems with multiple classes. The decision rule is based on the probability density function of the Gaussian distribution for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f38383e",
   "metadata": {},
   "source": [
    "### Q5. Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427660c4",
   "metadata": {},
   "source": [
    "I can guide you through the steps and provide code snippets for each section, but due to limitations in accessing external data or resources, I'm unable to directly download datasets or execute code that interacts with external sources.\n",
    "\n",
    "However, I'll provide an outline of the code structure you can use in your Jupyter Notebook:\n",
    "\n",
    "### Step-by-Step Code Structure:\n",
    "\n",
    "#### 1. Import necessary libraries:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "```\n",
    "\n",
    "#### 2. Load and preprocess the dataset:\n",
    "\n",
    "```python\n",
    "# Load the dataset using pandas read_csv\n",
    "# Replace 'path_to_dataset' with the path where you've saved the downloaded dataset\n",
    "data = pd.read_csv('path_to_dataset/spambase.csv')\n",
    "\n",
    "# Explore and preprocess the dataset (check for missing values, split into X and y, etc.)\n",
    "# Preprocess the data according to the requirements of Naive Bayes classifiers\n",
    "```\n",
    "\n",
    "#### 3. Implement Naive Bayes classifiers:\n",
    "\n",
    "```python\n",
    "# Separate features (X) and target variable (y)\n",
    "\n",
    "# Initialize Naive Bayes classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "# Perform 10-fold cross-validation for each classifier\n",
    "# Replace X and y with your feature and target variables\n",
    "scores_bernoulli = cross_val_score(bernoulli_nb, X, y, cv=10)\n",
    "scores_multinomial = cross_val_score(multinomial_nb, X, y, cv=10)\n",
    "scores_gaussian = cross_val_score(gaussian_nb, X, y, cv=10)\n",
    "```\n",
    "\n",
    "#### 4. Calculate Performance Metrics:\n",
    "\n",
    "```python\n",
    "# Compute performance metrics using classification_report for each classifier\n",
    "# Use X and y variables within classification_report\n",
    "report_bernoulli = classification_report(y, bernoulli_nb.fit(X, y).predict(X))\n",
    "report_multinomial = classification_report(y, multinomial_nb.fit(X, y).predict(X))\n",
    "report_gaussian = classification_report(y, gaussian_nb.fit(X, y).predict(X))\n",
    "```\n",
    "\n",
    "#### 5. Print Results and Discussion:\n",
    "\n",
    "```python\n",
    "# Print and analyze the performance metrics for each classifier\n",
    "print(\"Bernoulli Naive Bayes:\")\n",
    "print(scores_bernoulli)\n",
    "print(report_bernoulli)\n",
    "\n",
    "# Repeat the same for Multinomial and Gaussian Naive Bayes classifiers\n",
    "```\n",
    "\n",
    "#### 6. Conclusion and Suggestions:\n",
    "\n",
    "```python\n",
    "# Summarize the findings and provide suggestions for future work or improvements\n",
    "```\n",
    "\n",
    "Remember, the actual implementation will depend on the specifics of your dataset and how you preprocess the data for the Naive Bayes classifiers. Use appropriate feature extraction methods, handle missing values, and ensure data is properly formatted for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d173b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
